#!/usr/bin/env python3
"""
Threat Detection Framework
Detects and analyzes potential exploit delivery mechanisms
This module focuses on identifying suspicious patterns and behaviors
"""

import json
import hashlib
import re
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

class DeliveryMethod(Enum):
    EMAIL = "email"
    SMS = "sms"
    MESSAGING_APP = "messaging_app"
    WEB_LINK = "web_link"
    SOCIAL_MEDIA = "social_media"
    FILE_SHARING = "file_sharing"

class ThreatCategory(Enum):
    ZERO_CLICK = "zero_click"
    SOCIAL_ENGINEERING = "social_engineering"
    MALICIOUS_LINK = "malicious_link" 
    SUSPICIOUS_ATTACHMENT = "suspicious_attachment"
    PHISHING = "phishing"

@dataclass
class ThreatIndicator:
    indicator_type: str
    value: str
    confidence: float
    description: str
    first_seen: datetime
    threat_category: ThreatCategory

class ThreatDetectionEngine:
    """Engine for detecting potential threat delivery mechanisms"""
    
    def __init__(self):
        self.indicators = []
        self.detection_rules = self._load_detection_rules()
        self.analysis_cache = {}
    
    def _load_detection_rules(self) -> Dict[str, Dict]:
        """Load detection rules for various threat types"""
        return {
            'suspicious_urls': {
                'patterns': [
                    r'bit\.ly',
                    r'tinyurl\.com', 
                    r'[a-z0-9]{8,}\.tk',
                    r'[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}',
                    r'[a-z0-9-]+\.ddns\.net',
                ],
                'weight': 15
            },
            'suspicious_attachments': {
                'extensions': ['.exe', '.scr', '.bat', '.cmd', '.pif', '.vbs'],
                'weight': 25
            },
            'social_engineering_keywords': {
                'patterns': [
                    r'urgent.*click',
                    r'verify.*account',
                    r'suspended.*immediately',
                    r'limited.*time.*offer',
                    r'confirm.*identity',
                ],
                'weight': 10
            },
            'zero_click_indicators': {
                'patterns': [
                    r'unicode.*payload',
                    r'malformed.*image',
                    r'rtf.*exploit',
                    r'font.*overflow',
                ],
                'weight': 30
            }
        }
    
    def analyze_message(self, content: str, metadata: Dict = None) -> Dict:
        """Analyze a message for potential threats"""
        analysis = {
            'threat_score': 0,
            'detected_threats': [],
            'delivery_method': 'unknown',
            'confidence': 0.0,
            'recommendations': []
        }
        
        if not content:
            return analysis
        
        content_lower = content.lower()
        
        # Check for suspicious URLs
        for pattern in self.detection_rules['suspicious_urls']['patterns']:
            if re.search(pattern, content_lower):
                analysis['threat_score'] += self.detection_rules['suspicious_urls']['weight']
                analysis['detected_threats'].append({
                    'type': 'suspicious_url',
                    'pattern': pattern,
                    'description': 'Potentially malicious URL detected'
                })
        
        # Check for social engineering patterns
        for pattern in self.detection_rules['social_engineering_keywords']['patterns']:
            if re.search(pattern, content_lower):
                analysis['threat_score'] += self.detection_rules['social_engineering_keywords']['weight']
                analysis['detected_threats'].append({
                    'type': 'social_engineering',
                    'pattern': pattern,
                    'description': 'Social engineering language detected'
                })
        
        # Check for zero-click indicators
        for pattern in self.detection_rules['zero_click_indicators']['patterns']:
            if re.search(pattern, content_lower):
                analysis['threat_score'] += self.detection_rules['zero_click_indicators']['weight']
                analysis['detected_threats'].append({
                    'type': 'zero_click_indicator',
                    'pattern': pattern,
                    'description': 'Potential zero-click exploit indicator'
                })
        
        # Determine confidence level
        if analysis['threat_score'] >= 50:
            analysis['confidence'] = 0.9
            analysis['recommendations'].append('HIGH RISK: Isolate and investigate immediately')
        elif analysis['threat_score'] >= 25:
            analysis['confidence'] = 0.7
            analysis['recommendations'].append('MEDIUM RISK: Review and monitor closely')
        elif analysis['threat_score'] >= 10:
            analysis['confidence'] = 0.4
            analysis['recommendations'].append('LOW RISK: Continue monitoring')
        else:
            analysis['confidence'] = 0.1
            analysis['recommendations'].append('No immediate threats detected')
        
        return analysis
    
    def analyze_attachment(self, filename: str, file_data: bytes) -> Dict:
        """Analyze an attachment for potential threats"""
        analysis = {
            'filename': filename,
            'file_size': len(file_data),
            'file_hash': hashlib.sha256(file_data).hexdigest(),
            'threat_score': 0,
            'detected_threats': [],
            'file_type_analysis': {}
        }
        
        # Check file extension
        file_ext = filename.split('.')[-1].lower() if '.' in filename else ''
        
        if f'.{file_ext}' in self.detection_rules['suspicious_attachments']['extensions']:
            analysis['threat_score'] += self.detection_rules['suspicious_attachments']['weight']
            analysis['detected_threats'].append({
                'type': 'suspicious_extension',
                'value': file_ext,
                'description': f'Potentially dangerous file extension: .{file_ext}'
            })
        
        # Analyze file headers
        file_header = file_data[:16] if len(file_data) >= 16 else file_data
        
        # Check for common file signatures
        signatures = {
            b'MZ': 'PE executable',
            b'PK': 'ZIP/Office document', 
            b'\xff\xd8\xff': 'JPEG image',
            b'\x89PNG': 'PNG image',
            b'%PDF': 'PDF document'
        }
        
        for signature, description in signatures.items():
            if file_header.startswith(signature):
                analysis['file_type_analysis']['detected_type'] = description
                break
        
        # Check for embedded threats in images
        if 'image' in analysis['file_type_analysis'].get('detected_type', ''):
            suspicious_patterns = [
                b'\x00' * 50,  # Excessive null bytes
                b'\xff\xff\xff\xff',  # Potential overflow patterns
                b'script',  # Embedded scripts
            ]
            
            for pattern in suspicious_patterns:
                if pattern in file_data:
                    analysis['threat_score'] += 15
                    analysis['detected_threats'].append({
                        'type': 'suspicious_image_content',
                        'description': 'Suspicious patterns in image file'
                    })
                    break
        
        return analysis
    
    def scan_communication_channel(self, messages: List[Dict]) -> Dict:
        """Scan a communication channel for threat patterns"""
        scan_result = {
            'total_messages': len(messages),
            'threats_detected': 0,
            'threat_timeline': [],
            'overall_risk': 'low',
            'detailed_results': []
        }
        
        threat_scores = []
        
        for message in messages:
            content = message.get('content', '')
            timestamp = message.get('timestamp', datetime.now())
            
            analysis = self.analyze_message(content, message.get('metadata', {}))
            
            if analysis['threat_score'] > 0:
                scan_result['threats_detected'] += 1
                scan_result['threat_timeline'].append({
                    'timestamp': timestamp,
                    'threat_score': analysis['threat_score'],
                    'threats': analysis['detected_threats']
                })
            
            threat_scores.append(analysis['threat_score'])
            scan_result['detailed_results'].append(analysis)
        
        # Calculate overall risk
        if threat_scores:
            avg_score = sum(threat_scores) / len(threat_scores)
            max_score = max(threat_scores)
            
            if max_score >= 50 or avg_score >= 25:
                scan_result['overall_risk'] = 'high'
            elif max_score >= 25 or avg_score >= 10:
                scan_result['overall_risk'] = 'medium'
        
        return scan_result
    
    def generate_threat_report(self, analysis_results: List[Dict]) -> Dict:
        """Generate comprehensive threat analysis report"""
        report = {
            'summary': {
                'total_items_analyzed': len(analysis_results),
                'threats_detected': 0,
                'high_risk_items': 0,
                'medium_risk_items': 0,
                'low_risk_items': 0
            },
            'threat_categories': {},
            'recommendations': [],
            'technical_details': analysis_results
        }
        
        for result in analysis_results:
            threat_score = result.get('threat_score', 0)
            
            if threat_score > 0:
                report['summary']['threats_detected'] += 1
            
            if threat_score >= 50:
                report['summary']['high_risk_items'] += 1
            elif threat_score >= 25:
                report['summary']['medium_risk_items'] += 1  
            elif threat_score >= 10:
                report['summary']['low_risk_items'] += 1
            
            # Categorize threats
            for threat in result.get('detected_threats', []):
                threat_type = threat.get('type', 'unknown')
                if threat_type not in report['threat_categories']:
                    report['threat_categories'][threat_type] = 0
                report['threat_categories'][threat_type] += 1
        
        # Generate recommendations
        if report['summary']['high_risk_items'] > 0:
            report['recommendations'].append(
                'CRITICAL: Immediate investigation required for high-risk items'
            )
        
        if report['summary']['medium_risk_items'] > 0:
            report['recommendations'].append(
                'WARNING: Review medium-risk items and implement additional monitoring'
            )
        
        if report['summary']['threats_detected'] == 0:
            report['recommendations'].append(
                'CLEAR: No threats detected in analyzed content'
            )
        
        return report

def main():
    """Example usage of the threat detection engine"""
    detector = ThreatDetectionEngine()
    
    print("🔍 Threat Detection Engine")
    print("=" * 30)
    
    # Example message analysis
    suspicious_message = "URGENT: Your account will be suspended! Click here immediately: http://bit.ly/urgentverify"
    
    result = detector.analyze_message(suspicious_message)
    
    print(f"Message Analysis:")
    print(f"Threat Score: {result['threat_score']}")
    print(f"Confidence: {result['confidence']:.1%}")
    print(f"Detected Threats: {len(result['detected_threats'])}")
    
    for threat in result['detected_threats']:
        print(f"  - {threat['description']}")

if __name__ == "__main__":
    main()
